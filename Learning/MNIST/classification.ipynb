{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MNIST\n",
    "Author: Akaam Shamerany \\[@alpharoah GitHub\\]<br>Helpful resources: Hands On Machine Learning with Scikit-Learn, Keras and Tensorflow - Aurélien Géron\n",
    "\n",
    "<br>In this notebook, we will be using the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. \n",
    "\n",
    "<br>Scikit-Learn provides an easy way to download this dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "source": [
    "Datasets loaded by Scikit-Learn have similar dictionary structure including\n",
    "\n",
    "* A `DESCR` key describing the Datasets\n",
    "* A `data key` containing an array with one row per instance and one column per feature\n",
    "* A `target key` containing an array with the labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(70000, 784)\n(70000,)\n"
     ]
    }
   ],
   "source": [
    "#Lets look at the arrays:\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image is 28x28 pixels and each feature simply represents one pixel's intensity from 0 to 255 (white to black)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-28T18:26:02.614476</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 231.84 \nL 231.84 231.84 \nL 231.84 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#p019fd22b0b)\">\n    <image height=\"218\" id=\"image2030c84dd6\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p019fd22b0b\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(f\"\\n{y[0]}\") #Shows that this image is infact 5\n",
    "y = y.astype(np.uint8) #The output is a string, let's change it to type int (uint8)"
   ]
  },
  {
   "source": [
    "If you read our last Learning project, the housing model, we said that we should always create a test set and set it aside before inspecting the data closely. This MNIST dataset is actually already split into a training set and a test set (6:1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60_000], X[60_000:], y[:60_000], y[60_000:] #The training set is already shuffled for us"
   ]
  },
  {
   "source": [
    "## Training a Binary Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's simplify the problem and solve it so we can detect 5 and not 5. Let's create target vectors for this classification task:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True, False, False, ...,  True, False, False])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "y_train_5"
   ]
  },
  {
   "source": [
    "Let's pick a classifier and train it. A good place to start is with `Stochastic Gradient Descent (SGD)` classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "source": [
    "And now it's been trained! you can use it detect images of the number 5:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit]) # guessed that our image represents 5 (True)"
   ]
  },
  {
   "source": [
    "## Performance Measures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Evaluating classification is significantly harder than evaluating a regressor. There are many performance measures available.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Measuring Accuracy using Cross-Validation\n",
    "\n",
    "<br>Let's use `cross_val_score()` to evaluate our SGDClassifier model using K-fold cross-validation, using 3 folds."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "source": [
    "above 95% accuracy! Well, this is because only about 10% of the image are 5s, so if you always guess that an image is __*not*__ a 5, you will be right about it 90% of the time.\n",
    "\n",
    "<br>This is why accuracy is generally not the best way to measure performance for classifiers, especially when you are dealing with skewed datasets (i.e. when some classes are much more frequent than others)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "<br>Better way to measure performance of a classifier is to look at the confusion matrix.\n",
    "\n",
    "<br>The idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look into the 5th row and the 3rd column of the confusion matrix.\n",
    "\n",
    "<br>To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual target. You could make predicitons on the test set, but let's keep it untouched for now. Let's use `cross_val_predict()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=5)"
   ]
  },
  {
   "source": [
    "Now we are ready to get the confusion matrix using the `confusion_matrix()` function. We just need to pass it the target classes (y_train_5) and the predicted classes (y_train_pred)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[53115,  1464],\n",
       "       [  916,  4505]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "source": [
    "Each row represents a class and each column represents a predicted class. The first row of the matrix considers non-5 images (negative class): 53115 of them were correctly classified as non-5 (true negatives), while remaining 1464 were wrongly classified as 5s (false positives). The second rrow considers the images of 5s (positive class). 916 were wrongly classified as non-5's (false negatives) and 4505 were correctly classified as 5s (true positives). A perfect classifier would have only true positves and true negatives, so its confusion matrix would have non zero values only on its main diagonal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "y_train_perfect_predictions = y_train_5 #pretend we reached perfection\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)"
   ]
  },
  {
   "source": [
    "This is cool, but somteimes we may prefer a more concise metrix. Like the accuracy of the positive predictions, called __*precision*__ of the classifier\n",
    "\n",
    "<br> The equation for this is \n",
    "<br>precision = TP/(TP+FP)\n",
    "\n",
    "<br>Where TP is true positives and FP is false positives\n",
    "\n",
    "But if we have only a single positive prediction the precision would be 1/1 = 100%. This is not very useful and would ignore all but one positive instance. So precision is typically used along with another metix named recall (or sensitivity/true positive rate)\n",
    "\n",
    "<br> The equation for this is \n",
    "<br>precision = TP/(TP+FN)\n",
    "\n",
    "<br>Where TP is true positives and FP is false negatives\n",
    "\n",
    "<img src=\"./images/confusion_matrix.png\">\n",
    "\n",
    "This is an easier way to understand the confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Precision and Recall"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7547327860613168\n0.8310274857037447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_train_5, y_train_pred))\n",
    "print(recall_score(y_train_5, y_train_pred))"
   ]
  },
  {
   "source": [
    "Now when it claims an image represents a 5, it is correct 75% of the time and moreover, it detects 83% of the 5s.\n",
    "\n",
    "<br> it is often convenient to combine precision and recall into a single metric called the F_1 score. The F_1 (also known as the __*harmonic mean*__) gives much more weight to low values and as a result, the classifier will only get a high F_1 score if both recall and precision are high. The equation for F_1 is:\n",
    "\n",
    "<img src=\"./images/F_1equation.png\">\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.791044776119403"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "source": [
    "F_1 score favours calssifiers that have similar precision and recall. But this may not be what we want. In some contexts you might mostly care about precision, for example if you trained a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few bad videos show up in your product.\n",
    "\n",
    "<br>On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (There will be a few false alarms, but it will make sure that all shoplifters get caught)\n",
    "\n",
    "<br>However, you can't have it both ways: increasing precision reduces recall, and vice versa. This is called precision/recall tradoff  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Precision/recall tradeoff\n",
    "\n",
    "<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To understand this tradeoff, let's look at how the `SGDClassifier` makes its classification decisions. For each instance, it computes a score based on a `decision function`. If that score is greater than threshhold, it assigns the instance to the positive class, or else it assigns it to the negative class.\n",
    "\n",
    "<img src=\"./images/SGDClassifier_threshold.png\">\n",
    "\n",
    "<br>This picture shows a few digits positioned from the lowest score on the left to the highest score on the right. Suppose the `decision threshhold is positioned at the central arrow (between the two 5s): you will find 4 true positives (actual 5s) on the right of that threshhold, and one false positive (actually a 6). Therefore, with that threshhold, the precision is 80% (4/5). But out of 6 actual 5s, the classifier only detects 4, so the recall is 67% (4/6). Now if you raise the threshhold (move it to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall down to 50%. Conversely, lowering the threshhold increases recall and reduces precision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}